{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "febb5cb1",
   "metadata": {},
   "source": [
    "# Ames Housing Dataset – Description\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "> **Ames Housing Dataset** – real estate data from **Ames, Iowa (2006–2010)**  \n",
    "> Created by **Dean De Cock**  \n",
    "> Used in **Kaggle competition**: *House Prices: Advanced Regression Techniques*\n",
    "\n",
    "**Link to original competition:** [https://www.kaggle.com/c/house-prices-advanced-regression-techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques)\n",
    "\n",
    "---\n",
    "\n",
    "## Data characteristics\n",
    "\n",
    "| Property | Value |\n",
    "|--------|-------|\n",
    "| **Rows (houses)** | 2,930 |\n",
    "| **Features** | 79 (numeric, categorical, ordinal) |\n",
    "| **Target** | `SalePrice` (in USD) |\n",
    "| **Missing values** | Yes (requires imputation) |\n",
    "| **Time span** | 2006–2010 |\n",
    "\n",
    "---\n",
    "\n",
    "## Target Variable: `SalePrice`\n",
    "\n",
    "## Goal\n",
    "It is your job to predict the sales price for each house. For each Id in the test set, you must predict the value of the SalePrice variable. You want to test 3 predictive models: LASSO regression, random forest and deep neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5d0ca2",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "Results are evaluated on Root-Mean-Squared-Error (RMSE) between the logarithm of the predicted value and the logarithm of the observed sales price. (Taking logs means that errors in predicting expensive houses and cheap houses will affect the result equally). We also look at MAE. \n",
    "\n",
    "### **Matric formulas - quick recap**\n",
    "**MSE: Penalizes large errors (squared)**\n",
    "$$\n",
    "\\text{MSE} = \\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "**MAE: Robust to outliers (absolute)**\n",
    "$$\n",
    "\\text{MAE} = \\frac{1}{n}\\sum_{i=1}^{n} \\lvert y_i - \\hat{y}_i \\rvert\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3798212a",
   "metadata": {},
   "source": [
    "## Ames Housing Dataset — Variable Overview\n",
    "\n",
    "| Variable | Type | Description |\n",
    "|---|---|---|\n",
    "| `MSSubClass` | Nominal | Building class (e.g. 20 = 1-STORY 1946 & newer) |\n",
    "| `MSZoning` | Nominal | General zoning classification (e.g. RL, RM, etc.) |\n",
    "| `LotFrontage` | Continuous | Linear feet of street connected to property |\n",
    "| `LotArea` | Continuous | Lot size in square feet |\n",
    "| `Street` | Nominal | Type of road access (Grvl, Pave) |\n",
    "| `Alley` | Nominal | Type of alley access (Grvl, Pave, NA) |\n",
    "| `LotShape` | Nominal | General shape of the lot (Reg, IR1, IR2, IR3) |\n",
    "| `LandContour` | Nominal | Flatness of the property (Lvl, Bnk, HLS, Low) |\n",
    "| `Utilities` | Nominal | Type of utilities available (AllPub, NoSewr, etc.) |\n",
    "| `LotConfig` | Nominal | Lot configuration (Inside, Corner, CulDSac, etc.) |\n",
    "| `LandSlope` | Ordinal / Nominal | Slope of the property (Gtl, Mod, Sev) |\n",
    "| `Neighborhood` | Nominal | Physical location/neighborhood in Ames (e.g. Blmngtn, IDOTRR) |\n",
    "| `Condition1` | Nominal | Proximity to main road or railroad (primary) |\n",
    "| `Condition2` | Nominal | Proximity to main road or railroad (secondary) |\n",
    "| `BldgType` | Nominal | Type of dwelling (1Fam, Duplex, Townhouse, etc.) |\n",
    "| `HouseStyle` | Nominal | Style of house (1Story, 2Story, Split, etc.) |\n",
    "| `OverallQual` | Ordinal | Overall material & finish quality (1‑10) |\n",
    "| `OverallCond` | Ordinal | Overall condition rating (1‑10) |\n",
    "| `YearBuilt` | Numeric | Year the house was originally built |\n",
    "| `YearRemodAdd` | Numeric | Year of remodel/addition (or same as built if none) |\n",
    "| `RoofStyle` | Nominal | Type of roof (Flat, Gable, Hip, etc.) |\n",
    "| `RoofMatl` | Nominal | Roof material (Metal, Shingles, Tile, etc.) |\n",
    "| `Exterior1st` | Nominal | Exterior covering material on house |\n",
    "| `Exterior2nd` | Nominal | Exterior covering on second part (if more than one) |\n",
    "| `MasVnrType` | Nominal | Masonry veneer type (Brick, Stone, None, etc.) |\n",
    "| `MasVnrArea` | Numeric | Masonry veneer area in sq ft |\n",
    "| `ExterQual` | Ordinal | Exterior material quality (Ex, Gd, TA, Fa, Po) |\n",
    "| `ExterCond` | Ordinal | Current condition of the exterior (Ex, Gd, TA, etc.) |\n",
    "| `Foundation` | Nominal | Type of foundation (Brick, Poured, Wood, etc.) |\n",
    "| `BsmtQual` | Ordinal | Height of basement (Ex, Gd, TA, Fa, Po, NA) |\n",
    "| `BsmtCond` | Ordinal | Condition of basement (Ex, Gd, TA, etc.) |\n",
    "| `BsmtExposure` | Ordinal / Nominal | Walkout or garden level exposure (Gd, Av, Mn, No, NA) |\n",
    "| `BsmtFinType1` | Nominal | Type 1 finished basement area (GLQ, ALQ, Rec, etc.) |\n",
    "| `BsmtFinSF1` | Numeric | Square feet of type 1 finished basement area |\n",
    "| `BsmtFinType2` | Nominal | Type 2 finished basement (if present) |\n",
    "| `BsmtFinSF2` | Numeric | Square feet of type 2 finished basement area |\n",
    "| `BsmtUnfSF` | Numeric | Square feet of unfinished basement area |\n",
    "| `TotalBsmtSF` | Numeric | Total square feet of basement area |\n",
    "| `Heating` | Nominal | Type of heating (Gas, Floor, Wall, etc.) |\n",
    "| `HeatingQC` | Ordinal | Heating quality and condition (Ex, Gd, TA, Fa, Po) |\n",
    "| `CentralAir` | Nominal | Central air conditioning (Y/N) |\n",
    "| `Electrical` | Nominal | Electrical system (SBrkr, FuseA, FuseF, etc.) |\n",
    "| `1stFlrSF` | Numeric | First floor square feet |\n",
    "| `2ndFlrSF` | Numeric | Second floor square feet |\n",
    "| `LowQualFinSF` | Numeric | Low quality finished sq ft (all floors) |\n",
    "| `GrLivArea` | Numeric | Above grade (ground) living area sq ft |\n",
    "| `BsmtFullBath` | Discrete | Number of full bathrooms in basement |\n",
    "| `BsmtHalfBath` | Discrete | Number of half bathrooms in basement |\n",
    "| `FullBath` | Discrete | Number of full bathrooms above ground |\n",
    "| `HalfBath` | Discrete | Number of half bathrooms above ground |\n",
    "| `BedroomAbvGr` | Discrete | Number of bedrooms above basement level |\n",
    "| `KitchenAbvGr` | Discrete | Number of kitchens above ground |\n",
    "| `KitchenQual` | Ordinal | Kitchen quality (Ex, Gd, TA, Fa, Po) |\n",
    "| `TotRmsAbvGrd` | Discrete | Total rooms above ground (excluding bathrooms) |\n",
    "| `Functional` | Ordinal / Nominal | Home functionality rating (Typ, Min1, Maj1, etc.) |\n",
    "| `Fireplaces` | Discrete | Number of fireplaces |\n",
    "| `FireplaceQu` | Ordinal | Fireplace quality (Ex, Gd, TA, Fa, Po, NA) |\n",
    "| `GarageType` | Nominal | Garage location/type (Attchd, Detchd, Basment, etc.) |\n",
    "| `GarageYrBlt` | Numeric | Year garage was built |\n",
    "| `GarageFinish` | Nominal | Interior finish of the garage (Fin, RFn, Unf, NA) |\n",
    "| `GarageCars` | Discrete | Size of garage in car capacity |\n",
    "| `GarageArea` | Numeric | Size of garage in square feet |\n",
    "| `GarageQual` | Ordinal | Garage quality (Ex, Gd, TA, Fa, Po, NA) |\n",
    "| `GarageCond` | Ordinal | Garage condition (Ex, Gd, TA, Fa, Po, NA) |\n",
    "| `PavedDrive` | Nominal | Paved driveway (Y, P, N) |\n",
    "| `WoodDeckSF` | Numeric | Wood deck area in sq ft |\n",
    "| `OpenPorchSF` | Numeric | Open porch area in sq ft |\n",
    "| `EnclosedPorch` | Numeric | Enclosed porch area in sq ft |\n",
    "| `3SsnPorch` | Numeric | Three-season porch area in sq ft |\n",
    "| `ScreenPorch` | Numeric | Screen porch area in sq ft |\n",
    "| `PoolArea` | Numeric | Pool area in sq ft |\n",
    "| `PoolQC` | Ordinal | Pool quality (Ex, Gd, TA, Fa, NA) |\n",
    "| `Fence` | Nominal | Fence quality (GdPrv, MnPrv, etc.) |\n",
    "| `MiscFeature` | Nominal | Miscellaneous features (Elev, Shed, TenC, etc.) |\n",
    "| `MiscVal` | Numeric | Dollar value of miscellaneous feature |\n",
    "| `MoSold` | Discrete | Month sold (1–12) |\n",
    "| `YrSold` | Discrete | Year sold (2006–2010) |\n",
    "| `SaleType` | Nominal | Type of sale (WD, New, COD, etc.) |\n",
    "| `SaleCondition` | Nominal | Condition of sale (Normal, Abnorml, etc.) |\n",
    "| `SalePrice` | Numeric (target) | Sale price of the property in dollars |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1d56dd",
   "metadata": {},
   "source": [
    "## 1. Loading of packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c3803e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages for data processing (data frames etc.)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# packages for plots creation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# sklearn - package for LASSO regression and Random Forest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d97d9b-1901-4fc0-93ee-ac23e963774d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow - package for neural networks\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b4fad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# package for data imports from kaggle\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "# technical setting\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set(style='whitegrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24459d27-e44b-4966-af42-52524c40ec13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# package for model explanations\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a0e17f",
   "metadata": {},
   "source": [
    "## 2. Loading of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f369ef11",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"AmesHousing.csv\"\n",
    "df = kagglehub.load_dataset(\n",
    "    KaggleDatasetAdapter.PANDAS,\n",
    "    \"shashanknecrothapa/ames-housing-dataset\",\n",
    "    file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f4e97e",
   "metadata": {},
   "source": [
    "## 3. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7974fda8",
   "metadata": {},
   "source": [
    "#### 3.1. Removing variables with too many missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eecf427",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Code to show all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None) \n",
    "\n",
    "# With below code we can see how many missings are for each variable in the dataset\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adb718e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below we can see the exact shape of our data: (number of rows: data observations, number of columns: variables)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610f440c",
   "metadata": {},
   "source": [
    "Based on the above shape and observed numbers of missings, we can decide to drop all variables where number of missings is above 500. \n",
    "\n",
    "You can choose different number if you want to experiment.\n",
    "\n",
    "By the way it is important that our target variable (SalePrice) doesn't have missings - in case of missings of target variable, we would have to remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2435c1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "DROP_THRESHOLD = 500\n",
    "cols_to_drop = df.isnull().sum()[df.isnull().sum() > DROP_THRESHOLD].index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1104f02a",
   "metadata": {},
   "source": [
    "Below we can see which variables will be dropped with the chosen DROP_THRESHOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6d67dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c591f8e",
   "metadata": {},
   "source": [
    "Below we update our data frame - we get rid of cloumns with too many missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4a8346",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=cols_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb02b3e",
   "metadata": {},
   "source": [
    "#### 3.2. Imputation of missings\n",
    "\n",
    "For the variables that we decided to remain there are also missing values. We need to handle them.\n",
    "\n",
    "We have numerical variables - for them we can use one of the common techniques and just fulfill missings with median values from the whole dataset. \n",
    "\n",
    "We have also ordinal and categorical variables. For simplicity we will treat them the same and fill missings with mode. Quick recap of how they differ from each other is presented below.\n",
    "\n",
    "#####  Data Types: Numeric vs Categorical vs Ordinal\n",
    "\n",
    "| Data Type      | Description | Ordered? | Numeric Meaning? | Example |\n",
    "|----------------|-------------|----------|------------------|----------------|\n",
    "| **Numeric**    | Measurable values that support math operations. |  Yes |  Yes | height = 175.5 |\n",
    "| **Categorical** | Labels or groups with no inherent order. |  No |  No | color = \"red\", \"blue\", \"green\"|\n",
    "| **Ordinal**    | Categorical values with meaningful order but no numeric spacing. |  Yes |  No | size = \"small\", \"medium\", \"large\" |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50831b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median imputation for numerical variables\n",
    "\n",
    "med_cols = [\n",
    "    'Lot Frontage','Mas Vnr Area','BsmtFin SF 1','Garage Yr Blt',\n",
    "    'Garage Cars','Garage Area']\n",
    "\n",
    "for c in med_cols:\n",
    "    df[c] = df[c].fillna(df[c].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90512129",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Mode imputation for categorical and ordinal features (Mode means the most frequent value)\n",
    "\n",
    "mode_cols = [\n",
    "    'Bsmt Qual','Bsmt Cond','Bsmt Exposure','BsmtFin Type 1','BsmtFin Type 2',\n",
    "    'Bsmt Full Bath','Bsmt Half Bath','BsmtFin SF 2','Bsmt Unf SF',\n",
    "    'Total Bsmt SF','Electrical','Garage Type','Garage Finish',\n",
    "    'Garage Qual','Garage Cond','Utilities','Exterior 1st','Exterior 2nd',\n",
    "    'Kitchen Qual', \n",
    "]\n",
    "for c in mode_cols:\n",
    "    df[c] = df[c].fillna(df[c].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3809284",
   "metadata": {},
   "source": [
    "Below we can check if there are any missing values after our imputations. We should see 0 next to each variable - it means there are no missings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ea74f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e86ce41",
   "metadata": {},
   "source": [
    "#### 3.3.  Logarithmic transformation of house prices\n",
    "\n",
    "House prices are often transformed with logarithmic transformation before modelling. Logs were considered in the original Kaggle competition - lets use them also here. Below is short overview why logarithmic transformation of our target variable may be beneficial for us.\n",
    "\n",
    "Log-transforming house prices is common in modeling for several key reasons:\n",
    "\n",
    "1. **Reduce Skewness**  \n",
    "   - House prices are usually right-skewed (a few expensive houses create a long tail).  \n",
    "   - Log transformation compresses the right tail and makes the distribution closer to normal.\n",
    "\n",
    "2. **Stabilize Variance (Homoscedasticity)**  \n",
    "   - Variance often grows with the mean: expensive houses are more variable than cheap ones.  \n",
    "   - Log transform stabilizes variance, helping regression assumptions.\n",
    "\n",
    "3. **Linearize Relationships**  \n",
    "   - Many features affect price multiplicatively (e.g., `Price depends on Size^α`).  α is a parameter that we need to estimate.\n",
    "   - Log makes the relationship additive: `log(Price) depends on α * log(Size)`.\n",
    "\n",
    "4. **Equalize Relative Errors**  \n",
    "   - Predicting 10% too high for a cheap house and 10% too high for an expensive house has similar impact in log space.  \n",
    "   - In raw price, errors on expensive houses dominate the loss.\n",
    "\n",
    "5. **Interpretability**  \n",
    "   - Coefficients correspond to **percentage changes** in price.  \n",
    "   - Example: a coefficient of 0.05 → 1-unit increase in feature increases price by ~5%.\n",
    "\n",
    "---\n",
    "\n",
    "For simplicity of interpretation we will use back-transformation in the end - so we will see errors in thousands of $ anyway. But we still benefits from using log-transformation during modelling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba10f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code below computes log(x+1) \n",
    "# 1 is added to avoid having logarithm(0), which is undefined\n",
    "\n",
    "df['SalePrice_log'] = np.log1p(df['SalePrice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270b1181",
   "metadata": {},
   "source": [
    "#### 3.4. Division into train (60%), validation (20%) and test (20%) datasets \n",
    "\n",
    "In the first step we will train the models on train dataset and see how different sets of hyperparameters work on validation dataset. Then we will retrain our model for the best set of hyperparameters on train + validation dataset and see how it works on test dataset. \n",
    "\n",
    "We could use cross-validation, however neural networks training takes a lot of time and ofetn single splits of data are considered for NN training. We will use the same setup for each model, so the final results are fully comparable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ce8fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'SalePrice_log'\n",
    "X = df.drop(columns=['SalePrice','SalePrice_log'])\n",
    "y = df[target]\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=0.25, random_state=42)\n",
    "\n",
    "print(f\"Train: {X_train.shape[0]} | Val: {X_val.shape[0]} | Test: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234d86b7",
   "metadata": {},
   "source": [
    "#### 3.5. Encoding categorical and ordinal variables - replacing words with numbers\n",
    "\n",
    "We need to manually detect categorical and ordinal variables. Sometimes small number of unique values (e.g. \"small\" and \"big\") can point to the fact that the variable is ordinal, but it is no always the case. Fortunately someone has already detected categorical and ordinal variables. We create below lists:\n",
    "\n",
    "- categorical_cols: Selects all columns in X_train of type object (i.e., categorical).\n",
    "\n",
    "- ordinal_features: Manually specified ordinal categorical features (with meaningful order).\n",
    "\n",
    "- nominal_features: All remaining categorical features without order (pure labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e515b782",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# manually selected list of ordinal variables\n",
    "ordinal_features = ['Lot Shape','Utilities','Land Slope','Exter Qual','Exter Cond',\n",
    "                    'Heating QC','Electrical','Kitchen Qual','Functional','Paved Drive']\n",
    "\n",
    "# below list of categorical features, excluding ordinal ones\n",
    "nominal_features = [c for c in categorical_cols if c not in ordinal_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838d19b2",
   "metadata": {},
   "source": [
    "OrdinalEncoder: Maps ordered categories (like 'Poor' < 'Good' < 'Excellent') to integers (0, 1, 2, ...), creating one numeric column that preserves rank.\n",
    "\n",
    "OneHotEncoder: Converts unordered categories (like 'North', 'South') into multiple binary columns of 0s and 1s, where each column indicates the presence of a specific category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3937a9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We fit the encoder on train data and then apply tem to validation and test\n",
    "\n",
    "oe = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "oe.fit(X_train[ordinal_features])\n",
    "\n",
    "ohe = OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore')\n",
    "ohe.fit(X_train[nominal_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be51c674",
   "metadata": {},
   "source": [
    "Aplication of tranformations to different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478f7d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_split(df_split):\n",
    "    ord_arr = oe.transform(df_split[ordinal_features])\n",
    "    nom_arr = ohe.transform(df_split[nominal_features])\n",
    "    num_arr = df_split.select_dtypes(include=['int64','float64']).values\n",
    "    return np.hstack([num_arr, ord_arr, nom_arr])\n",
    "\n",
    "X_train_enc = encode_split(X_train)\n",
    "X_val_enc   = encode_split(X_val)\n",
    "X_test_enc  = encode_split(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db7db6a",
   "metadata": {},
   "source": [
    "#### 3.6. Applying standard scaler to the data - especially important for LASSO and neural networks\n",
    "We fit scaler on train dataset and then apply it on the validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e225f163",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_enc)\n",
    "X_val_scaled   = scaler.transform(X_val_enc)\n",
    "X_test_scaled  = scaler.transform(X_test_enc)\n",
    "\n",
    "print(f\"Final scaled shapes → train: {X_train_scaled.shape}  val: {X_val_scaled.shape}  test: {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d4c2da",
   "metadata": {},
   "source": [
    "## 4. Training of models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c228d084",
   "metadata": {},
   "source": [
    "#### 4.1 LASSO regression\n",
    "\n",
    "In our another excercise regularization hyperparameters was called lambda (λ), but here we refer to it as alpha. The naming may be different in different sources, but it is indeed the same regularization hyperparameter, so in LASSo alpha = lambda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ab5f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust number convention in python, so we see numbers in standard format (not scientific)\n",
    "np.set_printoptions(suppress=True, precision=6) \n",
    "\n",
    "# We define possible alpha (lambda) hyperparameters \n",
    "alphas = np.logspace(-4, 0, 15)\n",
    "alphas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a7bdf5",
   "metadata": {},
   "source": [
    "We select alpha hyperparameter, for which MAE on the validation dataset is the lowest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5478fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_scores = []\n",
    "\n",
    "for a in alphas:\n",
    "    model = Lasso(alpha=a, max_iter=20000, random_state=42)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    pred = model.predict(X_val_scaled)\n",
    "    mae = mean_absolute_error(np.expm1(y_val), np.expm1(pred))\n",
    "    lasso_scores.append((a, mae))\n",
    "\n",
    "best_alpha, best_lasso_mae = min(lasso_scores, key=lambda x: x[1])\n",
    "print(f\"Best LASSO alpha = {best_alpha:.5f} → Val MAE = ${best_lasso_mae:,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aaefc79",
   "metadata": {},
   "source": [
    "LASSO regression is a great benchmark for more complicated algorithms as random forests and neural networks. Thanks to monitoring of its performance we can really check if more advanced algorithms do a good job. If LASSO regression on test dataset is better or almost as good as more complicated algorithms there might be 2 reasons:\n",
    "- with the given data it is not possible to capture more complicated dependencies than linear one - LASSO is sufficient choice\n",
    "- you may need to adjust the more complicated models e.g. broaden search space of hyperparameters\n",
    "\n",
    "Let's see how LASSO performs against more complicated algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0874834a",
   "metadata": {},
   "source": [
    "#### 4.2 Random forest for regression\n",
    "\n",
    "We have already learned that single decision tree is not that good in prediction tasks due to its instability an tendency for overfit. Therefore we will consider random forest for regression.\n",
    "\n",
    "Below list rf_configs has already 3 sets of hyperparameters to be tested. Below is a quick recap what they mean. You can add more sets to be considered (but don't go with more than 20 due to computations time). We select set of hyperparameters, for which MAE on the validation dataset is the lowest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5209a61c",
   "metadata": {},
   "source": [
    "Random Forest Hyperparameters — Overview\n",
    "\n",
    "| Hyperparameter       | Description |\n",
    "|--------------------|-------------|\n",
    "| `n_estimators`      | Number of trees in the forest. More trees can improve performance but increase computation time. |\n",
    "| `max_depth`         | Maximum depth of each tree. Limits tree growth to prevent overfitting. |\n",
    "| `min_samples_split` | Minimum number of samples required to split an internal node. Higher values prevent splitting on small data, reducing overfitting. |\n",
    "| `min_samples_leaf`  | Minimum number of samples required to be at a leaf node. Ensures leaves have enough data points. |\n",
    "| `max_features`      | Number of features considered for splitting at each node. Can be an integer, float (fraction), `'sqrt'`, or `'log2'`. Controls randomness and diversity among trees. |\n",
    "| `bootstrap`         | Whether bootstrap samples are used when building trees (`True` = sampling with replacement, `False` = use whole dataset). |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c455ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_configs = [\n",
    "     #(n_estimators, max_depth, min_samples_split, min_samples_leaf, max_features, bootstrap)\n",
    "\n",
    "    (1000, None, 2, 1, 0.3,  False),   \n",
    "    (2000, None, 2, 1, 0.35, True),\n",
    "    (1500, None, 2, 1, 0.3,  False)    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60b7f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_scores = []\n",
    "for n_est, depth, min_split, min_leaf, max_feat, boot in rf_configs:\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=n_est,\n",
    "        max_depth=depth,\n",
    "        min_samples_split=min_split,\n",
    "        min_samples_leaf=min_leaf,\n",
    "        max_features=max_feat,\n",
    "        bootstrap=boot,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    pred = model.predict(X_val_scaled)\n",
    "    mae = mean_absolute_error(np.expm1(y_val), np.expm1(pred))\n",
    "    rf_scores.append((n_est, depth, min_split, min_leaf, max_feat, boot, mae))\n",
    "\n",
    "best_rf_cfg = min(rf_scores, key=lambda x: x[6])\n",
    "print(f\"Best RF: n_est={best_rf_cfg[0]}, depth={best_rf_cfg[1]}, \"\n",
    "      f\"split={best_rf_cfg[2]}, leaf={best_rf_cfg[3]}, \"\n",
    "      f\"feats={best_rf_cfg[4]}, boot={best_rf_cfg[5]} → Val MAE = ${best_rf_cfg[6]:,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fc9f6a",
   "metadata": {},
   "source": [
    "If we seek for an idea how to choose new sets of hyperparameters we can look into the performance of the sets that we have chosen so far. We might want to explore similar setups that are the best as of now. Below is code that ranks the perfomance of hyperparameter sets and also computes the validation MAE for each set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ee87df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build DataFrame with original index\n",
    "rf_df = pd.DataFrame(\n",
    "    rf_scores,\n",
    "    columns=['n_est','depth','split','leaf','feats','boot','mae']\n",
    ")\n",
    "rf_df.insert(0, 'orig_idx', range(1, len(rf_configs)+1))  # 1-based\n",
    "rf_df['orig_idx'] = rf_df['orig_idx'].astype(int)\n",
    "\n",
    "# Clean depth display\n",
    "rf_df['depth_str'] = rf_df['depth'].apply(lambda x: 'None' if x is None else str(x))\n",
    "\n",
    "# One-line description\n",
    "rf_df['desc'] = rf_df.apply(\n",
    "    lambda r: f\"{r.n_est} trees | depth={r.depth_str} | \"\n",
    "              f\"leaf={r.leaf} feats={r.feats} boot={r.boot}\",\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Top-20 by MAE\n",
    "top10_rf = rf_df.sort_values('mae').head(20).reset_index(drop=True)\n",
    "\n",
    "# Pretty print\n",
    "print(\"\\n=== TOP Random Forest configurations (by validation MAE) ===\")\n",
    "print(f\"{'#':>3}  {'Original #':>10}  {'MAE [$]':>12}  {'Config'}\")\n",
    "print(\"-\" * 85)\n",
    "for i, row in top10_rf.iterrows():\n",
    "    print(f\"{i+1:>2}.  #{row['orig_idx']:>8}  ${row['mae']:>10,.0f}  {row['desc']}\")\n",
    "\n",
    "# Best original index\n",
    "best_rf_orig_idx = top10_rf.iloc[0]['orig_idx']\n",
    "print(f\"\\nBest RF model is the **{best_rf_orig_idx}-th** entry in `rf_configs` \"\n",
    "      f\"(MAE = ${top10_rf.iloc[0]['mae']:,.0f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c397782",
   "metadata": {},
   "source": [
    "### Task: choose some more sets of hyperparameters for random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f79d35",
   "metadata": {},
   "source": [
    "#### 4.3 Neural network for regression\n",
    "\n",
    "We will try to setup deep (3-layers) neural network. Someone else has already done some research and setup an architecture that will be base for our further research. In the first step run the below code - you will see how long it takes for single neural network to be trained. Then go through the materials and explanation below, so you know how neural networks can be built in tensorflow keras. In the end you can add more networks to nn_grid to be tested (the same way as in case of random forest hyperparameters), but don't add more than 3 networks - it will take a lot of time to compute!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3215c3cf",
   "metadata": {},
   "source": [
    "Neural Network Hyperparameters — Overview\n",
    "\n",
    "| Hyperparameter  | Description |\n",
    "|-----------------|-------------|\n",
    "| `n1`            | Number of neurons in the **first hidden layer**. Controls model capacity. |\n",
    "| `n2`            | Number of neurons in the **second hidden layer**. Intermediate representation capacity. |\n",
    "| `n3`            | Number of neurons in the **third hidden layer**. Further abstraction of features. |\n",
    "| `dropout1`      | Dropout rate applied to the **first hidden layer**. Randomly drops this fraction of neurons during training to prevent overfitting. |\n",
    "| `dropout2`      | Dropout rate applied to the **second hidden layer**. Helps regularize deeper layers. |\n",
    "| `activation`    | Activation function used in hidden layers (e.g., `'gelu'`, `'relu'`). Introduces non-linearity to the network. |\n",
    "| `learning_rate` | Step size for the optimizer. Determines how fast the model updates weights during training. |\n",
    "| `batch_size`    | Number of samples processed before updating model weights. Smaller batch size = more updates per epoch; larger batch size = more stable gradients. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1146f686",
   "metadata": {},
   "source": [
    "In tensorflow keras the architecture of neural network is controlled with Sequential function. Lets break down how it works.\n",
    "\n",
    "Neural Network Model Construction — Overview\n",
    "\n",
    "The code builds a **feedforward neural network** using Keras `Sequential` API.\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "    model = Sequential([\n",
    "```        \n",
    "Below is the first layer of our NN. We set number of neurons (n1), activation function (act). Because it is our fist layer, we need to specify input shape, which is shape of our input data (219 columns after one hot encoding). In the end we need to have some initial weights before training - we use industry staple, so glorot_normal inicialization in the first layer, he_normal in the further layers.\n",
    "```        \n",
    "        Dense(n1, activation=act, input_shape=(X_train_scaled.shape[1],), kernel_initializer='glorot_normal'),\n",
    "```   \n",
    "Droput setup in the first layer. Randomly sets d1 fraction (e.g., 0.2 = 20%) of outputs to 0 during training - regularization hyperparameter\n",
    "\n",
    "```           \n",
    "        Dropout(d1), BatchNormalization(),\n",
    "``` \n",
    "The second layer with separate dropout setup.\n",
    "``` \n",
    "        Dense(n2, activation=act, kernel_initializer='he_normal'),\n",
    "        Dropout(d2), BatchNormalization(),\n",
    "``` \n",
    "The third layer with separate dropout setup - here we just set dropout to 0.1. It is possible to test only for some hyperparameters in neural network, and some consider fixed. Beside dropout below in our case fixed network element is number of layers (we consider 3 hidden layers). But you can experiment and e.g. add 4th hidden layer below :)\n",
    "```         \n",
    "        Dense(n3, activation=act, kernel_initializer='he_normal'),\n",
    "        Dropout(0.1), BatchNormalization(),\n",
    " ```  \n",
    " In the end we set the output layer. For regression we just set the Dense(1) which mean single neuron with no activation function\n",
    " ```  \n",
    "        Dense(1)\n",
    "    ])\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc58aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below is setup of the current network to be tested - currently there is only one\n",
    "\n",
    "nn_grid = [\n",
    "    #(n1, n2, n3, dropout1, dropout2, activation, learning_rate, batch_size)\n",
    "    (128, 64, 32, 0.20, 0.10, 'gelu', 0.0005, 64),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e81152e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_scores = []\n",
    "for n1, n2, n3, d1, d2, act, lr, batch in nn_grid:\n",
    "    model = Sequential([\n",
    "        Dense(n1, activation=act, input_shape=(X_train_scaled.shape[1],),\n",
    "              kernel_initializer='glorot_normal'),\n",
    "        Dropout(d1), BatchNormalization(),\n",
    "        Dense(n2, activation=act, kernel_initializer='he_normal'),\n",
    "        Dropout(d2), BatchNormalization(),\n",
    "        Dense(n3, activation=act, kernel_initializer='he_normal'),\n",
    "        Dropout(0.1), BatchNormalization(),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    \n",
    "    # Below we define optimizer. Adam optimizer is the variation of gradient descent - more advanced than the basic version. \n",
    "    # It works very similar to gradient descent.\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "        loss='mse', metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    # Below we setup callbacks, which monitor model training process. Thanks to them we know when testing error \n",
    "    # start to increase from epoch to epoch. In the end we can restore weights from epoch that was performing best on\n",
    "    # the validation dataset. The second callback modifies learning rate.\n",
    "    \n",
    "    # EarlyStopping: patience=50 → waits 50 epochs without improvement before stopping.\n",
    "    # restore_best_weights=True → after stopping, model weights revert to the epoch with the lowest validation loss\n",
    "\n",
    "    # ReduceLROnPlateau: Reduces the learning rate when validation loss stops improving.\n",
    "    # patience=15 → waits 15 epochs without improvement\n",
    "    # factor=0.5 → learning rate is multiplied by 0.5 (cut in half).\n",
    "    # min_lr=1e-7 → will not reduce LR below this minimum.\n",
    "    \n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7)\n",
    "    ]\n",
    "    \n",
    "    # Below we fit (train) our model. We set maximum number of epochs to 500. batch size is one of our hyperparameters. \n",
    "    \n",
    "    model.fit(\n",
    "        X_train_scaled, y_train,\n",
    "        validation_data=(X_val_scaled, y_val),\n",
    "        epochs=500, batch_size=batch,\n",
    "        callbacks=callbacks, verbose=0\n",
    "    )\n",
    "    \n",
    "    # Making predictions with the trained model\n",
    "    \n",
    "    pred = model.predict(X_val_scaled).flatten()\n",
    "    mae = mean_absolute_error(np.expm1(y_val), np.expm1(pred))\n",
    "    nn_scores.append((n1, n2, n3, d1, d2, act, lr, batch, mae))\n",
    "\n",
    "best_nn_cfg = min(nn_scores, key=lambda x: x[8])\n",
    "print(f\"Best NN: layers={best_nn_cfg[0:3]}, drop={best_nn_cfg[3:5]}, \"\n",
    "      f\"act={best_nn_cfg[5]}, lr={best_nn_cfg[6]}, batch={best_nn_cfg[7]} \"\n",
    "      f\"→ Val MAE = ${best_nn_cfg[8]:,.0f}\")\n",
    "\n",
    "# Below you can see 19/19 ... -> it is standard printed setup\n",
    "# The \"19/19\" means:\n",
    "#    19 → Number of mini-batches (steps) processed in this epoch\n",
    "#    19 → Total number of mini-batches in the training data\n",
    "# So: [current_step / total_steps] → 19/19 = epoch complete\n",
    "# In our code it is printed when the neural network is trained but remember that 19/19 batches goes through in each epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600835a7",
   "metadata": {},
   "source": [
    "Similarly as in case of random forest. If we seek for an idea how to choose new sets of hyperparameters we can look into the performance of the sets that we have chosen so far. We might want to explore similar setups that are the best as of now. Below is code that ranks the perfomance of hyperparameter sets and also computes the validation MAE for each set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa207ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a DataFrame that keeps the *original* index\n",
    "nn_df = pd.DataFrame(\n",
    "    nn_scores,\n",
    "    columns=['n1','n2','n3','d1','d2','act','lr','batch','mae']\n",
    ")\n",
    "nn_df.insert(0, 'orig_idx', range(1, len(nn_grid)+1))          # 1-based index\n",
    "nn_df['orig_idx'] = nn_df['orig_idx'].astype(int)\n",
    "\n",
    "# One-line description for nice printing\n",
    "nn_df['desc'] = nn_df.apply(\n",
    "    lambda r: f\"{r.n1}-{r.n2}-{r.n3} | drop({r.d1},{r.d2}) | \"\n",
    "              f\"{r.act} lr={r.lr} b={r.batch}\",\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Sort by MAE and keep only the top-10 (however in NNs I don't recommend you expanding above 4 - it will take a lot of time!)\n",
    "top10 = nn_df.sort_values('mae').head(10).reset_index(drop=True)\n",
    "\n",
    "# Pretty print\n",
    "print(\"\\n=== TOP Neural-Network configurations (by validation MAE) ===\")\n",
    "print(f\"{'#':>3}  {'Original #':>10}  {'MAE [$]':>12}  {'Config'}\")\n",
    "print(\"-\" * 80)\n",
    "for i, row in top10.iterrows():\n",
    "    print(f\"{i+1:>2}.  #{row['orig_idx']:>8}  ${row['mae']:>10,.0f}  {row['desc']}\")\n",
    "\n",
    "# 5. (optional) also return the best original index\n",
    "best_orig_idx = top10.iloc[0]['orig_idx']\n",
    "print(f\"\\nBest model is the **{best_orig_idx}-th** entry in `nn_grid` (MAE = ${top10.iloc[0]['mae']:,.0f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4dc970",
   "metadata": {},
   "source": [
    "### Task: choose at least one different architecture of neural network and compare it with the initial one. Try to find something that works better. Hint: more complicated neural network doesn't alwyas work better. Quite often simpler setups outperforms more complicated. Maybe try simpler activation function (relu is simpler than gelu). Maybe reduce number of neurons. mayber even reduce one hidden layer. Below find exemplary architecture, which you can treat as inspiration. But maybe in our case more complicated NN will be better? Lets find out!\n",
    "\n",
    "Original setup: \n",
    "(128, 64, 32, 0.20, 0.10, 'gelu', 0.0005, 64)\n",
    "\n",
    "Different setups for inspiration: \n",
    "\n",
    "(64, 32, 16, 0.30, 0.20, 'relu', 0.00025, 32)\n",
    "\n",
    "(32,16, 8, 0.20, 0.10, 'relu', 0.0004, 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2543a8f9",
   "metadata": {},
   "source": [
    "## 5. Re-train best models on train + validation (refit encoders + scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16553c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainval = pd.concat([X_train, X_val])\n",
    "y_trainval = pd.concat([y_train, y_val])\n",
    "\n",
    "# Refit encoders\n",
    "oe.fit(X_trainval[ordinal_features])\n",
    "ohe.fit(X_trainval[nominal_features])\n",
    "X_trainval_enc = encode_split(X_trainval)\n",
    "X_test_enc     = encode_split(X_test)\n",
    "\n",
    "# Refit scaler on train+val\n",
    "X_trainval_scaled = scaler.fit_transform(X_trainval_enc)\n",
    "X_test_scaled     = scaler.transform(X_test_enc)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# LASSO (unchanged)\n",
    "# -------------------------------------------------\n",
    "final_lasso = Lasso(alpha=best_alpha, max_iter=20000, random_state=42)\n",
    "final_lasso.fit(X_trainval_scaled, y_trainval)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Random Forest – now uses full best_rf_cfg\n",
    "# -------------------------------------------------\n",
    "n_est, depth, min_split, min_leaf, max_feat, boot = best_rf_cfg[:6]\n",
    "final_rf = RandomForestRegressor(\n",
    "    n_estimators=n_est,\n",
    "    max_depth=depth,\n",
    "    min_samples_split=min_split,\n",
    "    min_samples_leaf=min_leaf,\n",
    "    max_features=max_feat,\n",
    "    bootstrap=boot,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "final_rf.fit(X_trainval_scaled, y_trainval)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Neural Network – now uses full best_nn_cfg\n",
    "# -------------------------------------------------\n",
    "n1, n2, n3, d1, d2, act, lr, batch = best_nn_cfg[:8]\n",
    "final_nn = Sequential([\n",
    "    Dense(n1, activation=act, input_shape=(X_trainval_scaled.shape[1],),\n",
    "          kernel_initializer='glorot_normal'),\n",
    "    Dropout(d1), BatchNormalization(),\n",
    "    Dense(n2, activation=act, kernel_initializer='he_normal'),\n",
    "    Dropout(d2), BatchNormalization(),\n",
    "    Dense(n3, activation=act, kernel_initializer='he_normal'),\n",
    "    Dropout(0.1), BatchNormalization(),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Below for simplicity we setup EarlyStopping and ReduceLROnPlateau based just on train error - with our data it works fine (I have checked that :)\n",
    "# But there are several different strategies to choose the best number of epochs while preparing NN for deployment\n",
    "final_nn.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss='mse')\n",
    "final_nn.fit(\n",
    "    X_trainval_scaled, y_trainval,\n",
    "    epochs=500,\n",
    "    batch_size=batch,\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor='loss', patience=50, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='loss', factor=0.5, patience=15, min_lr=1e-7)\n",
    "    ],\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcba328",
   "metadata": {},
   "source": [
    "Below we can see plot Loss Curve for Final NN. We can see which epoch provided the best fit and how our training curve looks like. The plot of learning is much smoother than the examples from the power point presentation. Do you know why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21d0629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Get history from final training ===\n",
    "history = final_nn.history.history  # dict with 'loss', 'mae', etc.\n",
    "\n",
    "# Choose metric to plot ('loss' = MSE, 'mae' = MAE)\n",
    "metric = 'loss'  # or 'mae'\n",
    "\n",
    "# === Plot ===\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=history[metric], label=metric.upper(), lw=3, color='blue')\n",
    "\n",
    "# Smoothed curve (rolling mean, optional)\n",
    "window = 5\n",
    "smoothed = pd.Series(history[metric]).rolling(window=window).mean()\n",
    "sns.lineplot(data=smoothed, label=f'Smoothed {metric.upper()}', lw=2, ls='--', color='darkblue', alpha=0.7)\n",
    "\n",
    "# Mark best epoch (min loss)\n",
    "best_epoch = np.argmin(history[metric])\n",
    "best_value = history[metric][best_epoch]\n",
    "plt.scatter(best_epoch, best_value, color='red', s=100, label='Best Epoch', zorder=5)\n",
    "plt.text(best_epoch + 5, best_value, f\"Epoch {best_epoch}: {best_value:.4f}\", \n",
    "         fontsize=12, color='red', fontweight='bold')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(metric.upper())\n",
    "plt.title(f'Final NN Training Curve ({metric.upper()})', fontsize=16, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7311b7",
   "metadata": {},
   "source": [
    "## 6. Final check - lets see how our retrained models work on test dataset! Do you find results strange? Or they are in line with expectations?\n",
    "\n",
    "Error 15,000 means 15 000 - so our model is wrong on average by ~15 000 USD while predicting house prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ab18c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_dollars(y_true_log, y_pred_log):\n",
    "    return mean_absolute_error(np.expm1(y_true_log), np.expm1(y_pred_log))\n",
    "\n",
    "pred_lasso = final_lasso.predict(X_test_scaled)\n",
    "pred_rf    = final_rf.predict(X_test_scaled)\n",
    "pred_nn    = final_nn.predict(X_test_scaled).flatten()\n",
    "\n",
    "mae_lasso = mae_dollars(y_test, pred_lasso)\n",
    "mae_rf    = mae_dollars(y_test, pred_rf)\n",
    "mae_nn    = mae_dollars(y_test, pred_nn)\n",
    "\n",
    "mean_price = np.expm1(y_test).mean()\n",
    "\n",
    "rel_lasso = 100 * mae_lasso / mean_price\n",
    "rel_rf    = 100 * mae_rf    / mean_price\n",
    "rel_nn    = 100 * mae_nn    / mean_price\n",
    "\n",
    "print(f\"LASSO MAE         : ${mae_lasso:,.0f} ({rel_lasso:.1f}%)\")\n",
    "print(f\"Random Forest MAE : ${mae_rf:,.0f} ({rel_rf:.1f}%)\")\n",
    "print(f\"Neural Net MAE    : ${mae_nn:,.0f} ({rel_nn:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1d5632",
   "metadata": {},
   "source": [
    "## 7. Inspection of results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ac4bc1",
   "metadata": {},
   "source": [
    "#### 7.1 Plot of predictions vs true values for each model for both logarithmic scale and after back-transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5589e721",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3, figsize=(18,10))\n",
    "\n",
    "models = [\n",
    "    ('LASSO', pred_lasso, mae_lasso),\n",
    "    ('Random Forest', pred_rf, mae_rf),\n",
    "    ('Neural Net', pred_nn, mae_nn)\n",
    "]\n",
    "\n",
    "for i, (name, pred, mae) in enumerate(models):\n",
    "    # Log scale\n",
    "    ax = axs[0, i]\n",
    "    ax.scatter(y_test, pred, alpha=0.5, s=30)\n",
    "    ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "    ax.set_xlabel('True log-price')\n",
    "    ax.set_ylabel('Pred log-price')\n",
    "    ax.set_title(f'{name} (log)')\n",
    "\n",
    "    # Original $\n",
    "    ax = axs[1, i]\n",
    "    ax.scatter(np.expm1(y_test), np.expm1(pred), alpha=0.5, s=30)\n",
    "    ax.plot([0,800000],[0,800000],'r--')\n",
    "    ax.set_xlabel('True price [$]')\n",
    "    ax.set_ylabel('Pred price [$]')\n",
    "    ax.set_title(f'{name} – MAE = ${mae:,.0f}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feca6d46",
   "metadata": {},
   "source": [
    "#### 7.2 Inspection of 10 exemplary predictions for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4fae4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot 10 example predictions (True vs Predicted) – SAFE VERSION\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# === Re-create full predictions if they were sliced ===\n",
    "# (Run this block every time — it's safe!)\n",
    "pred_lasso_full = final_lasso.predict(X_test_scaled)\n",
    "pred_rf_full    = final_rf.predict(X_test_scaled)\n",
    "pred_nn_full    = final_nn.predict(X_test_scaled).flatten()\n",
    "\n",
    "# === Select 10 random houses from test set ===\n",
    "np.random.seed(42)\n",
    "sample_idx = np.random.choice(len(y_test), size=10, replace=False)\n",
    "sample_idx = np.sort(sample_idx)\n",
    "\n",
    "# === Extract values ===\n",
    "true_prices = np.expm1(y_test.iloc[sample_idx]).values\n",
    "pred_lasso  = np.expm1(pred_lasso_full[sample_idx])\n",
    "pred_rf     = np.expm1(pred_rf_full[sample_idx])\n",
    "pred_nn     = np.expm1(pred_nn_full[sample_idx])\n",
    "\n",
    "# === Plot ===\n",
    "sns.set(style=\"whitegrid\", font_scale=1.2)\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "x = np.arange(len(sample_idx))\n",
    "width = 0.2\n",
    "\n",
    "plt.bar(x - width, true_prices, width, label='True Price', color='lightgray', edgecolor='black')\n",
    "plt.bar(x,         pred_lasso,  width, label='LASSO',      color='steelblue', alpha=0.8)\n",
    "plt.bar(x + width, pred_rf,     width, label='Random Forest', color='forestgreen', alpha=0.8)\n",
    "plt.bar(x + 2*width, pred_nn,   width, label='Neural Net', color='darkorange', alpha=0.8)\n",
    "\n",
    "# === Add value labels ===\n",
    "def add_labels(values, offset, color='black'):\n",
    "    for i, v in enumerate(values):\n",
    "        plt.text(i + offset, v + 4000, f'${v:,.0f}', \n",
    "                 ha='center', va='bottom', fontsize=9, fontweight='bold', color=color)\n",
    "\n",
    "add_labels(true_prices, -width, 'black')\n",
    "#add_labels(pred_lasso, 0, 'steelblue')\n",
    "#add_labels(pred_rf, width, 'darkgreen')\n",
    "#add_labels(pred_nn, 2*width, 'darkorange')\n",
    "\n",
    "# === Formatting ===\n",
    "plt.xlabel('House Index (Test Sample)')\n",
    "plt.ylabel('House Price [$]')\n",
    "plt.title('10 Example Houses: True vs Predicted Prices', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xticks(x, [f'#{i+1}' for i in range(10)])\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "# === MAE summary box ===\n",
    "mae_text = (\n",
    "    f\"MAE Summary:\\n\"\n",
    "    f\"• LASSO:       ${mae_lasso:,.0f}\\n\"\n",
    "    f\"• RF:          ${mae_rf:,.0f}\\n\"\n",
    "    f\"• Neural Net:  ${mae_nn:,.0f}\"\n",
    ")\n",
    "plt.text(1.02, 0.7, mae_text, transform=plt.gca().transAxes,\n",
    "         fontsize=11, verticalalignment='center',\n",
    "         bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"lightyellow\", edgecolor=\"black\"))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7425ca8-42ae-4d80-ab17-879d8eac629f",
   "metadata": {},
   "source": [
    "#### 7.3 Permutation feature importance for all 3 final models - see which features are the most important for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5129da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build the full list of feature names after encoding\n",
    "\n",
    "#   • numeric columns (int64/float64)\n",
    "#   • ordinal columns → keep original name\n",
    "#   • one-hot columns → ohe.get_feature_names_out()\n",
    "\n",
    "numeric_cols   = X_trainval.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "ordinal_cols   = ordinal_features                                 # already a list\n",
    "nominal_cols   = nominal_features                                 # already a list\n",
    "\n",
    "# One-hot feature names (e.g. \"Neighborhood_North\", \"Bldg Type_2fmCon\")\n",
    "ohe_names = ohe.get_feature_names_out(nominal_cols)\n",
    "\n",
    "# Final ordered list (must match the order in encode_split!)\n",
    "feature_names = numeric_cols + ordinal_cols + ohe_names.tolist()\n",
    "\n",
    "# Sanity check\n",
    "assert len(feature_names) == X_trainval_scaled.shape[1], \\\n",
    "       f\"Name count {len(feature_names)} ≠ feature count {X_trainval_scaled.shape[1]}\"\n",
    "\n",
    "# Custom MAE-in-$ scorer \n",
    "\n",
    "def mae_dollars(model, X, y_log):\n",
    "    if hasattr(model, 'predict'):                     # sklearn\n",
    "        pred = model.predict(X)\n",
    "    else:                                            # Keras\n",
    "        pred = model(X, training=False).numpy().flatten()\n",
    "    return -mean_absolute_error(np.expm1(y_log), np.expm1(pred))\n",
    "\n",
    "# Compute permutation importance for the three models\n",
    "models = {\n",
    "    'Lasso'         : final_lasso,\n",
    "    'Random Forest' : final_rf,\n",
    "    'Neural Net'    : final_nn\n",
    "}\n",
    "\n",
    "X_eval = X_test_scaled[:500]      # small subset for speed (increase if you like)\n",
    "y_eval = y_test[:500]\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    perm = permutation_importance(\n",
    "        estimator=model,\n",
    "        X=X_eval,\n",
    "        y=y_eval,\n",
    "        scoring=mae_dollars,\n",
    "        n_repeats=5,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    df2 = pd.DataFrame({\n",
    "        'feature'    : feature_names,\n",
    "        'importance' : perm.importances_mean,\n",
    "        'std'        : perm.importances_std\n",
    "    }).sort_values('importance', ascending=False).head(15)\n",
    "    results[name] = df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d794b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 1, figsize=(10, 18))\n",
    "\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c']\n",
    "titles = ['Lasso', 'Random Forest', 'Neural Network']\n",
    "\n",
    "for ax, (name, df2), color, title in zip(axes, results.items(), colors, titles):\n",
    "    bars = ax.barh(df2['feature'], df2['importance'], xerr=df2['std'],\n",
    "                   color=color, edgecolor='black', alpha=0.85, capsize=5)\n",
    "    ax.set_title(f\"{title} – Top 15 Most Important Features\", fontsize=14, pad=15)\n",
    "    ax.set_xlabel(\"Mean |MAE| Increase When Shuffled ($)\", fontsize=12)\n",
    "    ax.grid(axis='x', linestyle='--', alpha=0.6)\n",
    "    ax.invert_yaxis() \n",
    "\n",
    "    # Add $ value labels\n",
    "    for bar in bars:\n",
    "        width = bar.get_width()\n",
    "        ax.text(width + 1000, bar.get_y() + bar.get_height()/2,\n",
    "                f'${width:,.0f}', va='center', ha='left', fontsize=9, fontweight='bold')\n",
    "\n",
    "plt.tight_layout(pad=4.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1041551-3230-4f80-935f-6e7cd2fa2d81",
   "metadata": {},
   "source": [
    "#### Questions\n",
    "Is any of the most important features among features, where missing values were replaced with median/mode at the beginning?\n",
    "\n",
    "Which model differs the most from others? \n",
    "\n",
    "Does the results make sense? Is there any feature that seem to be not important from your point of view and model treats it as important?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bf063b-1371-451a-a967-7cf6f86825f6",
   "metadata": {},
   "source": [
    "#### Bonus plot below - comparison of some features importance next to each other - so you can see how the results differ from each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e50f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot – three horizontal bar charts - with some common features (for comparison next to each other)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 7), sharey=True)\n",
    "\n",
    "for ax, (name, df2) in zip(axes, results.items()):\n",
    "    ax.barh(df2['feature'], df2['importance'], xerr=df2['std'],\n",
    "            color='steelblue', edgecolor='black')\n",
    "    ax.set_title(f\"{name}\\nPermutation Importance\", fontsize=13)\n",
    "    ax.set_xlabel(\"Mean |MAE| increase ($)\")\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "plt.suptitle(\"Feature Importance Comparison\", fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.94])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
