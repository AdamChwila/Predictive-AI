{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d248729",
   "metadata": {},
   "source": [
    "### K-Means → Image Segmentation\n",
    "\n",
    "Segmentation is the process of dividing an image into its fundamental (atomic) parts.\n",
    "\n",
    "It is useful for detecting basic objects in images — we first identify the objects and then classify them (e.g., determining whether a region is a face or not).\n",
    "\n",
    "It has primary applications in computer graphics, but is also widely used in other fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7d2528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing\n",
    "from PIL import Image\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f02d74",
   "metadata": {},
   "source": [
    "## Perform K-Means clustering on data extracted from an image (segmentation).\n",
    "\n",
    "Each pixel is represented as a point in $\\mathbb{R}^5$, where:\n",
    "\n",
    "the first 3 coordinates are the RGB color values,\n",
    "the last 2 coordinates are the pixel's position (x, y) in the image.\n",
    "\n",
    "\n",
    "\n",
    "Draw the segmented image by coloring all pixels in each cluster with a single representative color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bfeef2-b90b-487f-ab6f-3493fe68b87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw GitHub URL\n",
    "img_url = \"https://raw.githubusercontent.com/AdamChwila/Predictive-AI/main/stinkbug.png\"\n",
    "\n",
    "# Open the URL and load image\n",
    "with urllib.request.urlopen(img_url) as url:\n",
    "    img = Image.open(url)\n",
    "    img = np.array(img)  # convert to numpy array\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60c3c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_x, dim_y, _ = img.shape\n",
    "img_2d = np.array([np.append(img[i][j], [i, j]) for i in range(dim_x) for j in range(dim_y)])\n",
    "img_2d.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b24e909",
   "metadata": {},
   "source": [
    "Lets see how sinle point of the image looks as 5-element vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751b9f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first pixel representation\n",
    "img_2d[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d399f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the 100 000th pixel representation\n",
    "img_2d[100_000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc0acff",
   "metadata": {},
   "source": [
    "### We try to divide pixels into clusters - but the result is not so good ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77411468",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=2\n",
    "kmeans = KMeans(n_clusters=k).fit(img_2d)\n",
    "seg_img = [[kmeans.labels_[dim_y * i + j] / k for j in range(dim_y)] for i in range(dim_x)]\n",
    "plt.imshow(seg_img, cmap=plt.cm.viridis)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831c7234",
   "metadata": {},
   "source": [
    "The reason is that RGB color values (the first three components of the vector) are on a much smaller scale than the pixel coordinates (x, y positions in the image).\n",
    "\n",
    "As a result, the spatial positions dominate the K-means distance calculations, causing the algorithm to largely ignore the color information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199d592d",
   "metadata": {},
   "source": [
    "### Lets rescale the data - so the pixel coordinates and colors have similar impact on the final result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efe6304",
   "metadata": {},
   "source": [
    "### What is **Standard Scaler**?\n",
    "\n",
    "Transforms features to have mean = 0 and standard deviation = 1\n",
    "\n",
    "$$\n",
    "x_{\\text{scaled}} = \\frac{x - \\mu}{\\sigma}\n",
    "$$\n",
    "\n",
    "- `μ` = mean of the feature  \n",
    "- `σ` = standard deviation of the feature\n",
    "\n",
    "\n",
    "### Why Use It?\n",
    "\n",
    " Features on different scales (e.g., age: 0–100, income: 0–1M) after scaling are all on same scale \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777a150c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(img_2d)\n",
    "img_2d_standard_scaler = scaler.transform(img_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb3929d",
   "metadata": {},
   "source": [
    "### Lets compare how different vectors of our pixels look like before and after scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40ba503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# before scaling\n",
    "img_2d[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7e31fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after scaling\n",
    "img_2d_standard_scaler[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a73987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# before scaling\n",
    "img_2d[100_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14076dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after scaling\n",
    "img_2d_standard_scaler[100_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283ac627",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=2\n",
    "kmeans_standard_scaler = KMeans(n_clusters=k).fit(img_2d_standard_scaler)\n",
    "seg_img_standard_scaler = [[kmeans_standard_scaler.labels_[dim_y * i + j] / k for j in range(dim_y)] for i in range(dim_x)]\n",
    "plt.imshow(seg_img_standard_scaler, cmap=plt.cm.viridis)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048d6d82",
   "metadata": {},
   "source": [
    "### What happens if we increase the number of clusters in the above picture from 2 to larger numbers? Does larger numbers always improve the final result?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
